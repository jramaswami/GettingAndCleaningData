# Getting and Cleaning Data Course Project

## Introduction
These are all the files required for the course project for the Coursera
course Getting and Cleaning Data:

https://www.coursera.org/course/getdata

The data being analyzed is data is movement data from smartphones.  The
data was generated by researchers Jorge L. Reyes-Ortiz, Davide Anguita,
Alessandro Ghio, Luca Oneto and Xavier Parra from the 
martlab - Non-Linear Complex Systems Laboratory
DITEN - Università degli Studi di Genova, Genoa, Italy and
CETpD - Technical Research Centre for Dependency Care and Autonomous Living
Universitat Politècnica de Catalunya, Vilanova i la Geltrú, Spain

The researchers gathered data from the accelerometer and gyroscope
of smartphones worn by 30 volunteers while performing six activities:
walking, walking upstairs, walking downstairs, sitting, standing,
and laying.  They divided the data into test and training datasets
for the purposes of their research.  For this project, this division
has been undone and the test and training datasets have been recombined
into one dataset.

Our project requires that only the measurements on the mean and 
standard deviation for each measurement be extracted from the dataset 
for further analysis.  At first thought, this would be a process of
simply selecting columns that contain "mean" or "std".  However,
there are columns that are not mean or standard deviation measurements,
but instead are further analysis applied to measurements by the researchers
that retain "mean" or "std" in the column name.  These columns--which contain
"meanFreq" or "angle"--should not be included in our data for analysis.
(See data/raw/features_info.txt for more information on these columns.)

Once the appropriate columns were extracted, the data is to be tidied.
The intitial issue that jumped out was that the column names are values,
not variables.  Each measurement provided by the researchers can
be categorized in a number of ways:

1.  It is either time data or has had a Fast Fourier Transform applied.
2.  It is from the accelerometer and represents linear 
acceleration, or from the gyroscope and represents angular velocity, 
or has had further calculations done and represent linear jerk acceleration
, or angular jerk acceleration.
3.  Researchers took the original acceleration data and divided it into
components, so the measurement is either the gravitational component or the
estimated body component of acceleration.
4.  Researchers also divided the acceleration into the various vector
components: x direction, y direction, z direction, and magnitude.  So
a measurement is represents of these components.
5.  Finally, the measurement is a mean value or a standard deviation
value.

For example, one column in the raw data set is tGravityAcc-mean()-X.  
The value in the column represents the mean linear 
acceleration in the x direction of the gravity component without
the application of a Fast Fourier Transform (so it is time data).
The analysis script melts the data and transforms each of the 5 components
of the raw column name into a value leading to the transformation of:

| ... | tGravityAcc-mean()-X | ... |
|-----|----------------------|-----|
| ... |      0.3459274       | ... |

to

| ... | descriptive.statistic | input.type | acceleration.component | acceleration.type | vector.characteristic | ... |
|-----|-----------------------|------------|------------------------|-------------------|-----------------------|-----|
| ... |         MEAN          |    TIME    |         BODY           |       LINEAR      |           X           | ... |

The data was reshaped and the coded values placed into the appropriate
columns to create a "long" form of tidy data.  This was then grouped
and summarized to provide a mean value.

## Project Directory Structure

This project is organized in a manner that is based on the directory 
structure of an R package.

### R Scripts

All scripts are contained in the R/ directory.  To run them your working
directory should be the project's home, i.e. the directory containing this
README.md file.  

The R/download_data.R script will download the dataset
required for this project and place it in the data directory.  It will
record metadata about the download in the appropriate metadata.json file.
It will then unzip the data, delete unnecessary files.  It currently renames
the parent directory of the unzipped data to "raw" since that is more
descriptive.

The R/run_analysis.R script will clean the raw data, tidy it, and summarize
by calculating the mean values on the data when it is
grouped by subject, activity, descriptive 
statistic, input type, acceleration component, acceleration type, and
vector characteristic.  This summary data is then written to 
data/tidy/summary.dat using the write.table() function, as required.

### Data

The data directory contains all the data necessary for this project.
